bank.train = bank.data %>%
sample_frac(0.5)
bank.test = bank.data %>%
setdiff(bank.train)
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
#setup
set.seed(123)
library(readr)
library(tidyverse)
library(fastDummies)
library(knitr)
library(plyr)
library(dplyr)
library(explore)
library(corrplot)
library(ROCR)
library(cutpointr)
library(caret)
library(randomForest)
require(caTools)
library(rpart)
library(pROC)
#import dataset
bank.data <- read_delim("datasets/bank-full.csv",";", escape_double = FALSE, trim_ws = TRUE)
#clean NA vaules
bank.data = na.omit(bank.data)
#look at sample of our dataset
head(bank.data)
# modifying data set
#cat_data = data.frame(bank.data$job,bank.data$marital,bank.data$education)
#bin_cat_data = dummy_cols(cat_data)
#bin_cat_data = bin_cat_data %>% select(4:22)
#yesno_data = data.frame(bank.data$default,bank.data$housing,bank.data$loan,bank.data$y)
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("yes"=1))
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("no"=0))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("yes"=1))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("no"=0))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("yes"=1))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("no"=0))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("yes"=1))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("no"=0))
#remaining_data = bank.data %>% select(1,6,9,10,11,12,13,14,15,16)
#master_bin_data = cbind(bin_cat_data,yesno_data,remaining_data)
#head(master_bin_data)
#create test and train dataset
bank.train = bank.data %>%
sample_frac(0.5)
bank.test = bank.data %>%
setdiff(bank.train)
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
library(caret)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
#setup
set.seed(123)
library(readr)
library(tidyverse)
library(fastDummies)
library(knitr)
library(plyr)
library(dplyr)
library(explore)
library(corrplot)
library(ROCR)
library(cutpointr)
library(caret)
library(randomForest)
require(caTools)
library(rpart)
library(pROC)
#import dataset
bank.data <- read_delim("datasets/bank-full.csv",";", escape_double = FALSE, trim_ws = TRUE)
#clean NA vaules
bank.data = na.omit(bank.data)
#look at sample of our dataset
head(bank.data)
# modifying data set
#cat_data = data.frame(bank.data$job,bank.data$marital,bank.data$education)
#bin_cat_data = dummy_cols(cat_data)
#bin_cat_data = bin_cat_data %>% select(4:22)
#yesno_data = data.frame(bank.data$default,bank.data$housing,bank.data$loan,bank.data$y)
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("yes"=1))
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("no"=0))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("yes"=1))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("no"=0))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("yes"=1))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("no"=0))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("yes"=1))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("no"=0))
#remaining_data = bank.data %>% select(1,6,9,10,11,12,13,14,15,16)
#master_bin_data = cbind(bin_cat_data,yesno_data,remaining_data)
#head(master_bin_data)
#create test and train dataset
bank.train = bank.data %>%
sample_frac(0.5)
bank.test = bank.data %>%
setdiff(bank.train)
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
#make copy of data
lr.bank.data <- bank.train
#transform y into 1 and 0
lr.bank.data$y <- ifelse(lr.bank.data$y=='yes',1,0)
#create logistic model with all variables
logistic.model <- glm(as.factor(y)~., binomial(link = "logit"),lr.bank.data)
#summary of logistic model
summary(logistic.model)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
#make copy of data
lr.bank.data <- bank.train
#transform y into 1 and 0
lr.bank.data$y <- ifelse(lr.bank.data$y=='yes',1,0)
#create logistic model with all variables
logistic.model <- glm(as.factor(y)~., binomial(link = "logit"),lr.bank.data)
#summary of logistic model
summary(logistic.model)
#setup
set.seed(123)
library(readr)
library(tidyverse)
library(fastDummies)
library(knitr)
library(plyr)
library(dplyr)
library(explore)
library(corrplot)
library(ROCR)
library(cutpointr)
library(caret)
library(randomForest)
require(caTools)
library(rpart)
library(pROC)
#import dataset
bank.data <- read_delim("datasets/bank-full.csv",";", escape_double = FALSE, trim_ws = TRUE)
#clean NA vaules
bank.data = na.omit(bank.data)
#look at sample of our dataset
head(bank.data)
# modifying data set
#cat_data = data.frame(bank.data$job,bank.data$marital,bank.data$education)
#bin_cat_data = dummy_cols(cat_data)
#bin_cat_data = bin_cat_data %>% select(4:22)
#yesno_data = data.frame(bank.data$default,bank.data$housing,bank.data$loan,bank.data$y)
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("yes"=1))
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("no"=0))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("yes"=1))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("no"=0))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("yes"=1))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("no"=0))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("yes"=1))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("no"=0))
#remaining_data = bank.data %>% select(1,6,9,10,11,12,13,14,15,16)
#master_bin_data = cbind(bin_cat_data,yesno_data,remaining_data)
#head(master_bin_data)
#create test and train dataset
bank.train = bank.data %>%
sample_frac(0.5)
bank.test = bank.data %>%
setdiff(bank.train)
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
randomForest(as.factor(y)~., data = bank.train, importance= TRUE, mtry = 4,  ntree = 300)
dim(bank.trian)
dim(bank.train)
str(bank.train)
na.omit(bank.train)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
na.omit(bank.train)
rf <- randomForest(as.factor(y)~ ., data = na.omit(bank.train), importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
str(r)
str(y)
str(bank.train$y)
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
bank.train$y = ifelse(bank.train$y=="yes",1,0)
str(bank.train$y)
rf <- randomForest(as.factor(y)~ ., data = na.omit(bank.train), importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
rf <- randomForest(as.factor(y)~ ., newdata = (bank.train), importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
rf <- randomForest(as.factor(y)~ ., newdata = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
is.na(bank.train)
is.infinite(bank.train)
is.na(bank.train)
is.character(bank.train)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = 4, ntree = 300)
confusionMatrix(as.factor(bank.train$y), as.factor(pred))
dim(as.factor(bank.train$y))
dim(bank.train$y)
#setup
set.seed(123)
library(readr)
library(tidyverse)
library(fastDummies)
library(knitr)
library(plyr)
library(dplyr)
library(explore)
library(corrplot)
library(ROCR)
library(cutpointr)
library(caret)
library(randomForest)
require(caTools)
library(rpart)
library(pROC)
#import dataset
bank.data <- read_delim("datasets/bank-full.csv",";", escape_double = FALSE, trim_ws = TRUE)
#clean NA vaules
bank.data = na.omit(bank.data)
#look at sample of our dataset
head(bank.data)
# modifying data set
#cat_data = data.frame(bank.data$job,bank.data$marital,bank.data$education)
#bin_cat_data = dummy_cols(cat_data)
#bin_cat_data = bin_cat_data %>% select(4:22)
#yesno_data = data.frame(bank.data$default,bank.data$housing,bank.data$loan,bank.data$y)
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("yes"=1))
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("no"=0))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("yes"=1))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("no"=0))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("yes"=1))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("no"=0))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("yes"=1))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("no"=0))
#remaining_data = bank.data %>% select(1,6,9,10,11,12,13,14,15,16)
#master_bin_data = cbind(bin_cat_data,yesno_data,remaining_data)
#head(master_bin_data)
#create test and train dataset
bank.train = bank.data %>%
sample_frac(0.5)
bank.test = bank.data %>%
setdiff(bank.train)
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
dim(bank.train)
bank.train$y
dim(bank.train$y)
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
bank.test$y
bank.train$y = ifelse(bank.train$y=='yes',1,0)
bank.train$y
#setup
set.seed(123)
library(readr)
library(tidyverse)
library(fastDummies)
library(knitr)
library(plyr)
library(dplyr)
library(explore)
library(corrplot)
library(ROCR)
library(cutpointr)
library(caret)
library(randomForest)
require(caTools)
library(rpart)
library(pROC)
#import dataset
bank.data <- read_delim("datasets/bank-full.csv",";", escape_double = FALSE, trim_ws = TRUE)
#clean NA vaules
bank.data = na.omit(bank.data)
#look at sample of our dataset
head(bank.data)
# modifying data set
#cat_data = data.frame(bank.data$job,bank.data$marital,bank.data$education)
#bin_cat_data = dummy_cols(cat_data)
#bin_cat_data = bin_cat_data %>% select(4:22)
#yesno_data = data.frame(bank.data$default,bank.data$housing,bank.data$loan,bank.data$y)
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("yes"=1))
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("no"=0))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("yes"=1))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("no"=0))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("yes"=1))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("no"=0))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("yes"=1))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("no"=0))
#remaining_data = bank.data %>% select(1,6,9,10,11,12,13,14,15,16)
#master_bin_data = cbind(bin_cat_data,yesno_data,remaining_data)
#head(master_bin_data)
#create test and train dataset
bank.train = bank.data %>%
sample_frac(0.5)
bank.test = bank.data %>%
setdiff(bank.train)
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
bank.train$y = ifelse(bank.train$y=='yes',1,0)
bank.test$y
#make copy of data
lr.bank.data <- bank.train
#transform y into 1 and 0
lr.bank.data$y <- ifelse(lr.bank.data$y=='yes',1,0)
#create logistic model with all variables
logistic.model <- glm(as.factor(y)~., binomial(link = "logit"),lr.bank.data)
#summary of logistic model
summary(logistic.model)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
as.factor(bank.train$y)
as.factor(pred)
#Build logistic model with selected significant variables using AIC stepwise variable selection
logistic.model.AIC <- glm(y ~ duration + poutcome + month + contact + housing + job + campaign + loan + marital + day + education + balance, binomial(link = "logit"),lr.bank.data)
pred = format(round(predict(logistic.model.AIC, newdata = bank.test, type = "response")))
conf = table(pred, as.factor(bank.test$y));conf
#Tuning parameters
pred2 = predict(logistic.model.AIC, newdata = bank.test, type = "response")
pred.tune.log = prediction(pred2, bank.test$y)
perf.tune.log = performance(pred.tune.log, measure = "tpr", x.measure = "fpr")
accuracy.log = performance(pred.tune.log, measure = "acc", x.measure = "cutoff")
plot(accuracy.log)
plot(perf.tune.log) ##selecting default threshold value of 0.5
auc.log = as.numeric(performance(pred.tune.log, measure = "auc")@y.values)
auc.log
#Classification accuracy
(conf[1,1]+conf[2,2])/(sum(conf))
#Build logistic model with selected significant variables using AIC stepwise variable selection
logistic.model.AIC <- glm(y ~ duration + poutcome + month + contact + housing + job + campaign + loan + marital + day + education + balance, binomial(link = "logit"),lr.bank.data)
pred = format(round(predict(logistic.model.AIC, newdata = bank.test, type = "response")))
conf = table(pred, as.factor(bank.test$y));conf
#Tuning parameters
pred2 = predict(logistic.model.AIC, newdata = bank.test, type = "response")
pred.tune.log = prediction(pred2, bank.test$y)
perf.tune.log = performance(pred.tune.log, measure = "tpr", x.measure = "fpr")
accuracy.log = performance(pred.tune.log, measure = "acc", x.measure = "cutoff")
plot(accuracy.log)
plot(perf.tune.log) ##selecting default threshold value of 0.5
auc.log = as.numeric(performance(pred.tune.log, measure = "auc")@y.values)
auc.log
#Classification accuracy
(conf[1,1]+conf[2,2])/(sum(conf))
#setup
set.seed(123)
library(readr)
library(tidyverse)
library(fastDummies)
library(knitr)
library(plyr)
library(dplyr)
library(explore)
library(corrplot)
library(ROCR)
library(cutpointr)
library(caret)
library(randomForest)
require(caTools)
library(rpart)
library(pROC)
#import dataset
bank.data <- read_delim("datasets/bank-full.csv",";", escape_double = FALSE, trim_ws = TRUE)
#clean NA vaules
bank.data = na.omit(bank.data)
#look at sample of our dataset
head(bank.data)
# modifying data set
#cat_data = data.frame(bank.data$job,bank.data$marital,bank.data$education)
#bin_cat_data = dummy_cols(cat_data)
#bin_cat_data = bin_cat_data %>% select(4:22)
#yesno_data = data.frame(bank.data$default,bank.data$housing,bank.data$loan,bank.data$y)
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("yes"=1))
#yesno_data$bank.data.default <- revalue(yesno_data$bank.data.default, c("no"=0))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("yes"=1))
#yesno_data$bank.data.housing <- revalue(yesno_data$bank.data.housing, c("no"=0))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("yes"=1))
#yesno_data$bank.data.loan <- revalue(yesno_data$bank.data.loan, c("no"=0))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("yes"=1))
#yesno_data$bank.data.y <- revalue(yesno_data$bank.data.y, c("no"=0))
#remaining_data = bank.data %>% select(1,6,9,10,11,12,13,14,15,16)
#master_bin_data = cbind(bin_cat_data,yesno_data,remaining_data)
#head(master_bin_data)
#create test and train dataset
bank.train = bank.data %>%
sample_frac(0.5)
bank.test = bank.data %>%
setdiff(bank.train)
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
#make copy of data
lr.bank.data <- bank.train
#transform y into 1 and 0
lr.bank.data$y <- ifelse(lr.bank.data$y=='yes',1,0)
#create logistic model with all variables
logistic.model <- glm(as.factor(y)~., binomial(link = "logit"),lr.bank.data)
#summary of logistic model
summary(logistic.model)
both_AIC <- step(glm(y~1, binomial, lr.bank.data),
scope = ~age+job+marital+education+default+balance+housing+loan+contact+day+month+duration+campaign+pdays+previous+poutcome,
direction = "both")
both_AIC
#pdays, default, age, previous
#y ~ duration + poutcome + month + contact + housing + job + campaign + loan + marital + day + education + balance
#Build logistic model with selected significant variables using AIC stepwise variable selection
logistic.model.AIC <- glm(y ~ duration + poutcome + month + contact + housing + job + campaign + loan + marital + day + education + balance, binomial(link = "logit"),lr.bank.data)
pred = format(round(predict(logistic.model.AIC, newdata = bank.test, type = "response")))
conf = table(pred, as.factor(bank.test$y));conf
#Tuning parameters
pred2 = predict(logistic.model.AIC, newdata = bank.test, type = "response")
pred.tune.log = prediction(pred2, bank.test$y)
perf.tune.log = performance(pred.tune.log, measure = "tpr", x.measure = "fpr")
accuracy.log = performance(pred.tune.log, measure = "acc", x.measure = "cutoff")
plot(accuracy.log)
plot(perf.tune.log) ##selecting default threshold value of 0.5
auc.log = as.numeric(performance(pred.tune.log, measure = "auc")@y.values)
auc.log
#Classification accuracy
(conf[1,1]+conf[2,2])/(sum(conf))
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
library(randomForest)
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
rf1 = randomForest(y~., data = bank.train, importance = TRUE, mtry = 4, ntree = 300)
bank.train$y
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
rf1 = randomForest(y~., data = bank.train, importance = TRUE, mtry = 4, ntree = 300)
warnings()
lm1 = randomForest(as.factor(y)~., data = bank.train)
as.numeric(bank.train$y)
na.omit(bank.train$y)
lm1 = randomForest(as.factor(y)~., data = bank.train)
is.finite(bank.train$y)
is.infinite((bank.train$y))
is.infinite((bank.train$y==TRUE))
dec.tree = rpart(y~., data = bank.train, method="class"
)
prp(dec.tree, type = 2, extra = 104, fallen.leaves = TRUE)
dec.tree = rpart(y~., data = bank.train, method="class"
)
plot(dec.tree)
?ctree
install.packages("ctree")
library(rpart.plot)
dec.tree = rpart(y~., data = bank.train, method = "class")
dec.plot = rpart.plot(dec.tree)
?prp
dec.tree = rpart(y~., data = bank.train, method = "class")
dec.plot = prp(dec.tree, type = 2)
bank.train
dec.tree = rpart(y~., data = bank.train, method = "class")
dec.plot = prp(dec.tree, type = 2, extra = 104, fallen.leaves = TRUE)
dec.tree = rpart(as.factor(y)~., data = bank.train, method = "class")
dec.plot = prp(dec.tree, type = 2, extra = 104, fallen.leaves = TRUE)
dec.tree = rpart(as.factor(y)~., data = bank.train, method = "class")
dec.plot = prp(dec.tree, type = 2, extra = 104, fallen.leaves = TRUE)
dec.pred = predict(dec.tree, newdata = bank.test)
cm.dec = confusionMatrix(dec.pred, bank.test$y, positive = "yes")
cm.dec = confusionMatrix(dec.pred, bank.test$as.factor(y), positive = "yes")
yfac = as.factor(bank.test$y)
dec.tree = rpart(as.factor(y)~., data = bank.train, method = "class")
dec.plot = prp(dec.tree, type = 2, extra = 104, fallen.leaves = TRUE)
dec.pred = predict(dec.tree, newdata = bank.test)
yfac = as.factor(bank.test$y)
cm.dec = confusionMatrix(dec.pred, yfac, positive = "yes")
cm.dec = table(factor(dec.pred, levels = min(bank.test):max(bank.test)),
factor(test, levels=min(bank.test):max(bank.test)))
cm.dec = confusionMatrix(dec.pred, as.factor(bank.test$y), positive = "yes")
cm.dec = confusionMatrix(dec.pred, as.factor(bank.test$y))
cm.dec = confusionMatrix(dec.pred, as.factor(bank.test$y))
cm.dec = confusionMatrix((factor(dec.pred, levels=1:148,
factor(bank.test$y, levels = 1:148))))
dec.tree = rpart((y)~., data = bank.train, method = "class")
dec.plot = prp(dec.tree, extra = 104, fallen.leaves = TRUE)
dec.pred = predict(dec.tree, newdata = bank.test)
prop.table(table(bank.test))
prop.table(table(bank.test$y))
splot1 = sample.split(bank.data$y, SplitRatio = 0.7)
train = subset(bank.data, split==TRUE)
bank.data$y = ifelse(bank.data$y == 'yes', 1,0)
split
splot1
train1 = subset(bank.data, split == TRUE)
train1 = subset(bank.data, spl == TRUE)
train1 = subset(bank.data, splot1 == TRUE)
test1 = subset(bank.data, splot1 ==FALSE)
dt = rpart(y~., data = train1, method = "class")
prp(dt)
train1[c(1,6,10,12,13)] =scale(train1[c(1,6,10,12,13)])
test1[c(1,6,10,12,13)] = scale(test1[c1,6,10,12,13])
test1[c(1,6,10,12,13)] = scale(test1[c(1,6,10,12,13)])
dt = rpart(y~., data = train1, method = "class")
prp(dt)
test1[c(1,6,10,12,13)]
split = sample.split(bank.data$y, SplitRatio = 0.7)
bank.train = subset(bank.data, split ==TRUE)
bank.train[c(1:17)] = scale(bank.train[c(1:17)])
split = sample.split(bank.data$y, SplitRatio = 0.7)
bank.train = subset(bank.data, split ==TRUE)
bank.test = subset(bankk.data,split == FALSE)
split = sample.split(bank.data$y, SplitRatio = 0.7)
bank.train = subset(bank.data, split ==TRUE)
bank.test = subset(bank.data,split == FALSE)
#create random forest model with all variables, mtry = sqrt(p) for classification
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
bank.train = bank.data %>%
sample_frac(0.5)
bank.test = bank.data %>%
setdiff(bank.train)
bank.test$y <- ifelse(bank.test$y=='yes',1,0)
split1 = sample.split(bank.data$y, SplitRatio = 0.7)
dec.tree = rpart((y)~., data = bank.train, method = "class")
dec.plot = prp(dec.tree, extra = 104, fallen.leaves = TRUE)
dec.pred = predict(dec.tree, newdata = bank.test)
#create random forest model with all variables, mtry = sqrt(p) for classification
rf <- randomForest(as.factor(y)~ ., data = bank.train, importance = TRUE, mtry = sqrt(dim(bank.train)[2]-1), ntree = 300)
dec.tree = rpart((y)~., data = bank.train, method = "class")
dec.plot = prp(dec.tree, fallen.leaves = TRUE)
dec.pred = predict(dec.tree, newdata = bank.test)
dec.tree = tree(y~., bank.train)
tree
?tree
library(xfun)
dec.tree = tree(y~., bank.train)
dec.tree = tree(y~., bank.train)
plot(dec.tree)
dec.tree = rpart(y~., data=bank.train, method = "class")
rpart(dec.tree)
